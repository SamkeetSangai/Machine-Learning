{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VTn2PvSgN0i",
        "outputId": "528850d0-f551-45dc-af9f-1cfb5205bd06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-26 17:45:58--  https://www.gutenberg.org/files/1661/1661-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607430 (593K) [text/plain]\n",
            "Saving to: ‘book.txt’\n",
            "\n",
            "book.txt            100%[===================>] 593.19K  1.71MB/s    in 0.3s    \n",
            "\n",
            "2022-10-26 17:45:59 (1.71 MB/s) - ‘book.txt’ saved [607430/607430]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.gutenberg.org/files/1661/1661-0.txt -O book.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('book.txt','r',encoding='utf-8').read()\n",
        "text = text.lower()"
      ],
      "metadata": {
        "id": "duRZjatdhAbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text.split('\\n')"
      ],
      "metadata": {
        "id": "7s-LM8cZhXeK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "jXxKbDQbhfL6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<UNK>')"
      ],
      "metadata": {
        "id": "gs90nFK8ijai"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA1wTKvolCQM",
        "outputId": "685d908b-ab30-4d71-fa3d-4e40dfb25d85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8915"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "t3hdvjVHlpl0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "  for i in range(1,len(sequence)):\n",
        "    n_gram_sequence = sequence[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "Wye1oJHRmUy8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = max([len(seq) for seq in input_sequences])\n",
        "max_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1xL8Z-onLPk",
        "outputId": "c339dade-f00e-46a2-acae-b72ec3f4d642"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequences(input_sequences,maxlen=max_seq_len)"
      ],
      "metadata": {
        "id": "fPzQXfmincFf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "padded_sequences = np.array(padded_sequences)"
      ],
      "metadata": {
        "id": "ITNE7bQRoDXI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_sequences[:,:-1]\n",
        "lables = padded_sequences[:,-1]"
      ],
      "metadata": {
        "id": "17jnZi6-oLO4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(lables,num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "gv8KwS5kosoD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding ,Bidirectional, LSTM, Dense"
      ],
      "metadata": {
        "id": "kA8RlgcHpMCi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,100,input_length=max_seq_len-1))\n",
        "model.add(Bidirectional(LSTM(256)))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS5cVuqxp-Xv",
        "outputId": "889865ed-06e7-4168-b21a-8d172469d1ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 19, 100)           891500    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 512)              731136    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8915)              4573395   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,196,031\n",
            "Trainable params: 6,196,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='acc',min_delta=0.001)"
      ],
      "metadata": {
        "id": "yQA0Azzpq7ve"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=20,verbose=1,batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTfMR5OXrjs5",
        "outputId": "00569a46-49db-4268-f1e3-679055aeb5af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "199/199 [==============================] - 15s 35ms/step - loss: 6.2071 - acc: 0.0839\n",
            "Epoch 2/20\n",
            "199/199 [==============================] - 7s 35ms/step - loss: 5.3030 - acc: 0.1429\n",
            "Epoch 3/20\n",
            "199/199 [==============================] - 7s 35ms/step - loss: 4.7794 - acc: 0.1710\n",
            "Epoch 4/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 4.2776 - acc: 0.2002\n",
            "Epoch 5/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 3.7838 - acc: 0.2418\n",
            "Epoch 6/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 3.3439 - acc: 0.2927\n",
            "Epoch 7/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 2.9653 - acc: 0.3461\n",
            "Epoch 8/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 2.6540 - acc: 0.3968\n",
            "Epoch 9/20\n",
            "199/199 [==============================] - 7s 37ms/step - loss: 2.4059 - acc: 0.4400\n",
            "Epoch 10/20\n",
            "199/199 [==============================] - 7s 37ms/step - loss: 2.2036 - acc: 0.4765\n",
            "Epoch 11/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 2.0403 - acc: 0.5074\n",
            "Epoch 12/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.8994 - acc: 0.5342\n",
            "Epoch 13/20\n",
            "199/199 [==============================] - 7s 37ms/step - loss: 1.7778 - acc: 0.5603\n",
            "Epoch 14/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.6852 - acc: 0.5776\n",
            "Epoch 15/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.5974 - acc: 0.5957\n",
            "Epoch 16/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.5386 - acc: 0.6076\n",
            "Epoch 17/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.4830 - acc: 0.6179\n",
            "Epoch 18/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.4298 - acc: 0.6296\n",
            "Epoch 19/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.3799 - acc: 0.6404\n",
            "Epoch 20/20\n",
            "199/199 [==============================] - 7s 36ms/step - loss: 1.3612 - acc: 0.6439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8eb65dcb90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speed_text = \"I could not help laughing at the ease with which he explained his process of deduction\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "  sequence = tokenizer.texts_to_sequences([speed_text])\n",
        "  padded = pad_sequences(sequence,maxlen=max_seq_len-1)\n",
        "  predict_x = model.predict(padded) \n",
        "  classes_x = np.argmax(predict_x,axis=1)\n",
        "  output_word = ''\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == classes_x:\n",
        "      output_word = word\n",
        "      break\n",
        "  speed_text += ' ' + output_word\n",
        "print(speed_text)"
      ],
      "metadata": {
        "id": "GaHHaLN7r6Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14dee726-7a7c-4c61-e028-993407ee6494"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 653ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "I could not help laughing at the ease with which he explained his process of deduction “when i have heard mr holmes that i have scored over you ” he answered ringing the whole bag “the miss questioning glances up in the centre of the room waiting maid took out his coronet and of arthur’s face nosed dressed into a boot lace their care in amid an excessive anderson of smoke these road—249 where represents the morning of the vault or the songs and shouts of solid 1888—i was returning from one to the other pausing only at ten and in the pew of a invention of bicycling etc and the paper in his head and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbU4thzC7fGv"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}