{"cells":[{"cell_type":"markdown","metadata":{},"source":["Default code from kaggle"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:16:08.741762Z","iopub.status.busy":"2022-10-24T19:16:08.741337Z","iopub.status.idle":"2022-10-24T19:17:02.233805Z","shell.execute_reply":"2022-10-24T19:17:02.232657Z","shell.execute_reply.started":"2022-10-24T19:16:08.741731Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        os.path.join(dirname, filename)\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Getting list of all possible outputs as keys and images of same class as values"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:02.236267Z","iopub.status.busy":"2022-10-24T19:17:02.235856Z","iopub.status.idle":"2022-10-24T19:17:02.276897Z","shell.execute_reply":"2022-10-24T19:17:02.275617Z","shell.execute_reply.started":"2022-10-24T19:17:02.236230Z"},"trusted":true},"outputs":[],"source":["import csv\n","\n","data = {}\n","with open(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\") as f:\n","    reader = csv.reader(f)\n","    next(reader)\n","    for row in reader:\n","        key = row[1].lower()\n","        if key in data:\n","            data[key].append(row[2])\n","        else:\n","            data[key] = [row[1]]"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:02.279589Z","iopub.status.busy":"2022-10-24T19:17:02.278686Z","iopub.status.idle":"2022-10-24T19:17:02.287356Z","shell.execute_reply":"2022-10-24T19:17:02.285983Z","shell.execute_reply.started":"2022-10-24T19:17:02.279538Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["driver_actions_list = list(data.keys())\n","driver_actions_list"]},{"cell_type":"markdown","metadata":{},"source":["Creating necessary folders"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:02.291856Z","iopub.status.busy":"2022-10-24T19:17:02.290952Z","iopub.status.idle":"2022-10-24T19:17:03.329689Z","shell.execute_reply":"2022-10-24T19:17:03.328560Z","shell.execute_reply.started":"2022-10-24T19:17:02.291802Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","shutil.rmtree('master_data', ignore_errors=True)\n","shutil.rmtree('predict', ignore_errors=True)\n","\n","os.mkdir('master_data')\n","os.mkdir('master_data/training')\n","os.mkdir('master_data/testing')\n","\n","os.mkdir('predict')\n","os.mkdir('predict/all_class')"]},{"cell_type":"markdown","metadata":{},"source":["Creating necessary sub-folders"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:03.331731Z","iopub.status.busy":"2022-10-24T19:17:03.331261Z","iopub.status.idle":"2022-10-24T19:17:03.339805Z","shell.execute_reply":"2022-10-24T19:17:03.338632Z","shell.execute_reply.started":"2022-10-24T19:17:03.331681Z"},"trusted":true},"outputs":[],"source":["for action in driver_actions_list:\n","    os.mkdir(os.path.join('master_data/training',action))\n","    os.mkdir(os.path.join('master_data/testing',action))"]},{"cell_type":"markdown","metadata":{},"source":["Dividing data (80% for training and 20% for validation)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:03.342949Z","iopub.status.busy":"2022-10-24T19:17:03.342595Z","iopub.status.idle":"2022-10-24T19:17:30.675992Z","shell.execute_reply":"2022-10-24T19:17:30.674980Z","shell.execute_reply.started":"2022-10-24T19:17:03.342919Z"},"trusted":true},"outputs":[],"source":["from shutil import copyfile\n","split_size = 0.8\n","\n","for file in os.listdir('../input/state-farm-distracted-driver-detection/imgs/train'):\n","    file_path = '../input/state-farm-distracted-driver-detection/imgs/train'+'/{}'.format(file)\n","    images = os.listdir(file_path)\n","    train_size = int(split_size*len(images))\n","    train_images = images[:train_size]\n","    test_images = images[train_size:]\n","    \n","    for image in train_images:\n","        source = os.path.join(file_path,image)\n","        dest = os.path.join('./master_data/training',file,image)\n","        copyfile(source,dest)\n","    \n","    for image in test_images:\n","        source = os.path.join(file_path,image)\n","        dest = os.path.join('./master_data/testing',file,image)\n","        copyfile(source,dest)"]},{"cell_type":"markdown","metadata":{},"source":["Importing necessary Libraries"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:30.680531Z","iopub.status.busy":"2022-10-24T19:17:30.680082Z","iopub.status.idle":"2022-10-24T19:17:30.687529Z","shell.execute_reply":"2022-10-24T19:17:30.685632Z","shell.execute_reply.started":"2022-10-24T19:17:30.680496Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"]},{"cell_type":"markdown","metadata":{},"source":["Creating CNN Model"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:30.690030Z","iopub.status.busy":"2022-10-24T19:17:30.689237Z","iopub.status.idle":"2022-10-24T19:17:31.012013Z","shell.execute_reply":"2022-10-24T19:17:31.011118Z","shell.execute_reply.started":"2022-10-24T19:17:30.689993Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_12 (Conv2D)           (None, 128, 128, 64)      832       \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 64, 64, 128)       32896     \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 32, 32, 256)       131328    \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 16, 16, 512)       524800    \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 32768)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 512)               16777728  \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 17,472,714\n","Trainable params: 17,472,714\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = tf.keras.models.Sequential([\n","    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(128,128,3), kernel_initializer='glorot_normal'),\n","    MaxPooling2D(2,2),\n","    Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'),\n","    MaxPooling2D(2,2),\n","    Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'),\n","    MaxPooling2D(2,2),\n","    Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'),\n","    MaxPooling2D(2,2),\n","    Dropout(0.5),\n","    Flatten(),\n","    Dense(512,activation='relu', kernel_initializer='glorot_normal'),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax', kernel_initializer='glorot_normal')\n","])\n","model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy',metrics= ['acc'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Using ImageDataGenerator for image processing"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:31.014587Z","iopub.status.busy":"2022-10-24T19:17:31.013424Z","iopub.status.idle":"2022-10-24T19:17:32.181407Z","shell.execute_reply":"2022-10-24T19:17:32.179935Z","shell.execute_reply.started":"2022-10-24T19:17:31.014549Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 17934 images belonging to 10 classes.\n","Found 4490 images belonging to 10 classes.\n"]}],"source":["train_dir = './master_data/training'\n","test_dir = './master_data/testing'\n","\n","train_datagen = ImageDataGenerator(rescale=1.0/255)\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size = (128,128),\n","    class_mode = 'categorical',\n","    batch_size = 128\n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1.0/255)\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size = (128,128),\n","    class_mode = 'categorical',\n","    batch_size = 128\n",")"]},{"cell_type":"markdown","metadata":{},"source":["EarlyStopping if model is not improving for 2 epochs continuously"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:32.185041Z","iopub.status.busy":"2022-10-24T19:17:32.184659Z","iopub.status.idle":"2022-10-24T19:17:32.190830Z","shell.execute_reply":"2022-10-24T19:17:32.189162Z","shell.execute_reply.started":"2022-10-24T19:17:32.185010Z"},"trusted":true},"outputs":[],"source":["es = EarlyStopping(monitor='val_acc',patience=4,min_delta=0.01)"]},{"cell_type":"markdown","metadata":{},"source":["Model Training"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T19:17:32.192125Z","iopub.status.busy":"2022-10-24T19:17:32.191811Z","iopub.status.idle":"2022-10-24T21:10:19.743198Z","shell.execute_reply":"2022-10-24T21:10:19.741690Z","shell.execute_reply.started":"2022-10-24T19:17:32.192097Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","141/141 [==============================] - 679s 5s/step - loss: 4.5685 - acc: 0.1685 - val_loss: 1.4595 - val_acc: 0.5203\n","Epoch 2/10\n","141/141 [==============================] - 681s 5s/step - loss: 1.3523 - acc: 0.5267 - val_loss: 0.7606 - val_acc: 0.7684\n","Epoch 3/10\n","141/141 [==============================] - 675s 5s/step - loss: 0.8950 - acc: 0.7044 - val_loss: 0.4625 - val_acc: 0.8873\n","Epoch 4/10\n","141/141 [==============================] - 672s 5s/step - loss: 0.7177 - acc: 0.7666 - val_loss: 0.2976 - val_acc: 0.9285\n","Epoch 5/10\n","141/141 [==============================] - 672s 5s/step - loss: 0.6039 - acc: 0.8080 - val_loss: 0.3206 - val_acc: 0.9134\n","Epoch 6/10\n","141/141 [==============================] - 674s 5s/step - loss: 0.5687 - acc: 0.8152 - val_loss: 0.2569 - val_acc: 0.9396\n","Epoch 7/10\n","141/141 [==============================] - 672s 5s/step - loss: 0.4988 - acc: 0.8410 - val_loss: 0.1858 - val_acc: 0.9572\n","Epoch 8/10\n","141/141 [==============================] - 675s 5s/step - loss: 0.4886 - acc: 0.8450 - val_loss: 0.1917 - val_acc: 0.9503\n","Epoch 9/10\n","141/141 [==============================] - 673s 5s/step - loss: 0.4513 - acc: 0.8556 - val_loss: 0.1861 - val_acc: 0.9577\n","Epoch 10/10\n","141/141 [==============================] - 678s 5s/step - loss: 0.4139 - acc: 0.8676 - val_loss: 0.1634 - val_acc: 0.9604\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f3d7906f450>"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(\n","    train_generator,\n","    epochs=10,\n","    verbose=1,\n","    validation_data=test_generator,\n","    callbacks=[es],\n","    shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["Copying images to seprate folder for prediction"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T21:42:02.439356Z","iopub.status.busy":"2022-10-24T21:42:02.438864Z","iopub.status.idle":"2022-10-24T21:46:44.198670Z","shell.execute_reply":"2022-10-24T21:46:44.197603Z","shell.execute_reply.started":"2022-10-24T21:42:02.439317Z"},"trusted":true},"outputs":[],"source":["origin = '../input/state-farm-distracted-driver-detection/imgs/test/'\n","target = './predict/all_class/'\n","\n","files = os.listdir(origin)\n","\n","images_name = []\n","for file_name in files:\n","    shutil.copy(origin+file_name,target+file_name)\n","    images_name.append(file_name)"]},{"cell_type":"markdown","metadata":{},"source":["Using ImageDataGenerator for image processing"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T21:47:21.059833Z","iopub.status.busy":"2022-10-24T21:47:21.059399Z","iopub.status.idle":"2022-10-24T21:47:23.233729Z","shell.execute_reply":"2022-10-24T21:47:23.232377Z","shell.execute_reply.started":"2022-10-24T21:47:21.059799Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 79726 images belonging to 1 classes.\n"]}],"source":["predict_dir = './predict/'\n","\n","predict_datagen = ImageDataGenerator(rescale=1.0/255)\n","predict_generator = predict_datagen.flow_from_directory(\n","    predict_dir,\n","    target_size = (128,128),\n","    class_mode = None,\n","    batch_size = 128\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Image prediction"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T21:58:31.337048Z","iopub.status.busy":"2022-10-24T21:58:31.336646Z","iopub.status.idle":"2022-10-24T22:14:07.506570Z","shell.execute_reply":"2022-10-24T22:14:07.505260Z","shell.execute_reply.started":"2022-10-24T21:58:31.337008Z"},"trusted":true},"outputs":[],"source":["filenames = predict_generator.filenames\n","nb_samples = len(filenames)\n","\n","predict = model.predict(predict_generator,nb_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T22:28:32.632043Z","iopub.status.busy":"2022-10-24T22:28:32.631221Z","iopub.status.idle":"2022-10-24T22:28:32.649804Z","shell.execute_reply":"2022-10-24T22:28:32.648265Z","shell.execute_reply.started":"2022-10-24T22:28:32.632004Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame(predict, columns=['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9'])\n","df.insert(loc = 0,column='img',value=images_name)\n","df.head()"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2022-10-24T22:25:30.344414Z","iopub.status.busy":"2022-10-24T22:25:30.343975Z","iopub.status.idle":"2022-10-24T22:25:31.272565Z","shell.execute_reply":"2022-10-24T22:25:31.271544Z","shell.execute_reply.started":"2022-10-24T22:25:30.344380Z"},"trusted":true},"outputs":[],"source":["df.to_csv('submission.csv',index=False,header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
